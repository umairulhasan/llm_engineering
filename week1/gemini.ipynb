{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5521877a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='That\\'s a fantastic question! \"How AI works\" can seem complex, but at its core, the idea is quite intuitive. Let\\'s break it down into simple concepts.\\n\\nThink of it like this: **Traditional computer programs follow exact instructions you give them.** For example, \"If the button is clicked, show a message.\"\\n\\n**AI, especially modern AI (Machine Learning), is different.** Instead of being explicitly told every single rule, **AI learns from data, just like a human learns from experience.**\\n\\nHere\\'s a step-by-step breakdown of how most modern AI (specifically Machine Learning) works:\\n\\n---\\n\\n### The Core Idea: Learning from Data\\n\\nImagine you want to teach a child to identify a \"cat.\"\\n\\n1.  **You don\\'t give them a list of rules** (\"a cat has whiskers, pointy ears, fur, a tail...\"). That would be incredibly hard and probably incomplete.\\n2.  **Instead, you show them many, many pictures:** \"This is a cat. This is also a cat. This is *not* a cat (it\\'s a dog). This is a cat...\"\\n3.  **Over time, the child starts to recognize patterns** – the general shape, the features, how they combine – and can then identify new, unseen cats.\\n\\n**AI works in a very similar way.**\\n\\n---\\n\\n### The 4 Key Steps of AI (Machine Learning)\\n\\n1.  **Data Collection (The \"Experience\"):**\\n    *   AI needs a *massive* amount of information related to the task it needs to perform.\\n    *   **Examples:**\\n        *   **For image recognition:** Millions of images labeled \"cat,\" \"dog,\" \"tree,\" etc.\\n        *   **For language translation:** Billions of sentences translated between languages.\\n        *   **For predicting house prices:** Data on house size, number of rooms, location, past sale prices.\\n    *   **Quality is crucial:** If the data is biased or incorrect, the AI will learn those biases or inaccuracies.\\n\\n2.  **Training (The \"Learning\" Process):**\\n    *   This is where the magic happens. The AI uses **algorithms** (which are just sets of mathematical instructions) to process the collected data.\\n    *   The algorithm looks for patterns, correlations, and relationships within the data.\\n    *   **Imagine the AI as a student trying to build a model (a mathematical representation) of the world based on the data.**\\n    *   **How it learns:**\\n        *   It makes a prediction based on what it\\'s seen so far.\\n        *   It compares its prediction to the *actual* answer in the data.\\n        *   If it\\'s wrong, it adjusts its internal \"parameters\" (like knobs on a complex machine) slightly to get closer to the right answer next time.\\n        *   This process is repeated millions or billions of times, gradually refining its model.\\n    *   **This learning process is what allows AI to find complex patterns that would be impossible for a human to explicitly program.**\\n\\n3.  **Model (The \"Learned Knowledge\"):**\\n    *   Once training is complete, the AI has a \"model.\" This model is essentially the compressed knowledge it gained from the data.\\n    *   It\\'s not a list of \"if-then\" rules; it\\'s more like a complex mathematical function or a network of interconnected \"neurons\" (in the case of Neural Networks/Deep Learning).\\n    *   This model can now generalize from what it has learned.\\n\\n4.  **Prediction/Inference (Putting Knowledge to Use):**\\n    *   Now, you can give the trained AI *new, unseen data* (data it wasn\\'t trained on).\\n    *   The AI will use its learned model to make a prediction, classification, or decision based on that new data.\\n    *   **Examples:**\\n        *   You show it a new image, and it predicts whether it\\'s a cat or a dog.\\n        *   You type a sentence in English, and it translates it into Spanish.\\n        *   You input details about a new house, and it predicts its selling price.\\n\\n---\\n\\n### What\\'s Under the Hood? (A Quick Peek)\\n\\n*   **Algorithms:** These are the specific mathematical procedures AI uses to learn. There are many types:\\n    *   **Neural Networks (and Deep Learning):** Inspired by the human brain, these are layers of interconnected \"nodes\" that process information in stages. Deep Learning just means *many* layers. This is what powers most of the impressive AI we see today (image recognition, natural language processing).\\n    *   **Decision Trees:** Like a flowchart for decisions.\\n    *   **Regression:** For predicting numerical values (like house prices).\\n    *   **Clustering:** For finding groups or segments within data.\\n*   **Computational Power:** Training AI models requires immense computing power (often specialized hardware called GPUs) because of the sheer volume of data and the number of calculations involved.\\n*   **Data Science & Engineering:** Humans are still crucial for collecting, cleaning, and preparing data, choosing the right algorithms, and evaluating the AI\\'s performance.\\n\\n---\\n\\n### In Simple Terms:\\n\\n**AI isn\\'t programmed with every answer; it\\'s programmed to *learn* the answers by finding patterns in vast amounts of information.** It\\'s like teaching a student by showing them many examples until they figure out the underlying principles themselves, rather than giving them a rulebook.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"AIzaSyBAzdO9HItLQ5KBCSP_u8Ac5Z2lTjzxDMM\",\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain to me how AI works\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f89448ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f276903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect ollama \n",
    "\n",
    "# MODEL = 'gpt-4o-mini'\n",
    "# openai = OpenAI()\n",
    "MODEL = \"llama3.2\"\n",
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a9c1690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect google generative AI\n",
    "\n",
    "google_client = OpenAI(\n",
    "    api_key=\"AIzaSyBAzdO9HItLQ5KBCSP_u8Ac5Z2lTjzxDMM\",\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a1eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with links\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192d62e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ed = Website(\"https://edwarddonner.com\")\n",
    "ed.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "565a8116",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00080a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(link_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91441147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c71c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_links_user_prompt(ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e413c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    response = ollama.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "      ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a9c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_links(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39c120d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents() \n",
    "    links = get_links(url)\n",
    "    print(\"Found links:\", links)\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += Website(link[\"url\"]).get_contents()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d595e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_all_details(\"https://edwarddonner.com\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81cb7202",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\"\n",
    "\n",
    "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
    "\n",
    "# system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "# and creates a short humorous, entertaining, jokey brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8a7daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd4f332c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'Company page', 'url': 'https://edwarddonner.com/'}, {'type': 'About page', 'url': 'https://edwarddonner.com/about-me-and-about-nebula/'}, {'type': 'Home page', 'url': 'https://edwarddonner.com/'}, {'type': 'LinkedIn profile', 'url': 'https://www.linkedin.com/in/eddonner/'}, {'type': 'Twitter profile', 'url': 'https://twitter.com/edwarddonner'}, {'type': 'Facebook profile', 'url': 'https://www.facebook.com/edward.donner.52'}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You are looking at a company called: HuggingFace\\nHere are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\nLanding page:\\nWebpage Title:\\nHome - Edward Donner\\nWebpage Contents:\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nWell, hi there.\\nI’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\\nvery\\namateur) and losing myself in\\nHacker News\\n, nodding my head sagely to things I only half understand.\\nI’m the co-founder and CTO of\\nNebula.io\\n. We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\\nacquired in 2021\\n.\\nWe work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\\npatented\\nour matching model, and our award-winning platform has happy customers and tons of press coverage.\\nConnect\\nwith me for more!\\nMay 28, 2025\\nConnecting my courses – become an LLM expert and leader\\nMay 18, 2025\\n2025 AI Executive Briefing\\nApril 21, 2025\\nThe Complete Agentic AI Engineering Course\\nJanuary 23, 2025\\nLLM Workshop – Hands-on with Agents – resources\\nNavigation\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nGet in touch\\ned [at] edwarddonner [dot] com\\nwww.edwarddonner.com\\nFollow me\\nLinkedIn\\nTwitter\\nFacebook\\nSubscribe to newsletter\\nType your email…\\nSubscribe\\n\\n\\n\\nCompany page\\nWebpage Title:\\nHome - Edward Donner\\nWebpage Contents:\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nWell, hi there.\\nI’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\\nvery\\namateur) and losing myself in\\nHacker News\\n, nodding my head sagely to things I only half understand.\\nI’m the co-founder and CTO of\\nNebula.io\\n. We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\\nacquired in 2021\\n.\\nWe work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\\npatented\\nour matching model, and our award-winning platform has happy customers and tons of press coverage.\\nConnect\\nwith me for more!\\nMay 28, 2025\\nConnecting my courses – become an LLM expert and leader\\nMay 18, 2025\\n2025 AI Executive Briefing\\nApril 21, 2025\\nThe Complete Agentic AI Engineering Course\\nJanuary 23, 2025\\nLLM Workshop – Hands-on with Agents – resources\\nNavigation\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nGet in touch\\ned [at] edwarddonner [dot] com\\nwww.edwarddonner.com\\nFollow me\\nLinkedIn\\nTwitter\\nFacebook\\nSubscribe to newsletter\\nType your email…\\nSubscribe\\n\\n\\n\\nAbout page\\nWebpage Title:\\nAbout - Edward Donner\\nWebpage Contents:\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nAbout\\nI’m the co-founder and CTO of\\nNebula.io\\n. We help recruiters source, understand, engage and manage talent, using Generative AI and other forms of machine learning. Our\\npatented\\nmodel matches people with roles with greater accuracy and speed than previously imaginable — no keywords required. Take a look for yourself; it’s completely free to try.\\nOur long term goal is to help people discover their potential and pursue their reason for being, motivated by a concept called\\nIkigai\\n. We help people find roles where they will be most fulfilled and successful; as a result, we will raise the level of human prosperity. It sounds grandiose, but since 77% of people don’t consider themselves\\ninspired or engaged\\nat work, it’s completely within our reach.\\nI sometimes have to pinch myself. I’m incredibly lucky to be working in the field of AI at a time when it’s rewriting the boundaries of human and tech possibilities. I’m personally most drawn to applying AI to real world problems, and the specific problem of hiring has plagued me throughout my career. So I’m in the business of finding people their dream jobs — and conveniently, I’m in my dream job myself.\\nBefore Nebula.io\\nYou can trace the roots of Nebula.io to an AI startup I founded in 2013 called\\nuntapt\\n. We built talent marketplaces and data science software for recruitment firms. To start with, we specialized on tech roles in financial services, where there was a huge suppl'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_brochure_user_prompt(\"HuggingFace\", \"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d93fde54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "    response = ollama.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbfb285e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://edwarddonner.com/about-me-and-about-nebula/'}, {'type': 'home page', 'url': 'https://edwarddonner.com/'}, {'type': 'careers/ jobs page', 'url': 'https://www.linkedin.com/in/eddonner/'}, {'type': 'company/about company', 'url': 'https://nebula.io/?utm_source=ed&utm_medium=referral'}]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Brochure: HuggingFace**\n",
       "===============\n",
       "\n",
       "**Welcome to HuggingFace**\n",
       "\n",
       "HuggingFace is a company that harnesses the power of Artificial Intelligence (AI) to make a positive impact on one's potential and pursuits. As a pioneer in the field of large language model (LLM) training, we are dedicated to democratizing access to state-of-the-art AI technology.\n",
       "\n",
       "**Our Mission**\n",
       "\n",
       "At HuggingFace, our mission is to help people discover their potential and pursue their reason for being by providing cutting-edge AI-powered solutions for talent management. Our patented matching model enables recruiters to source, understand, engage, and manage talent with unprecedented accuracy and speed.\n",
       "\n",
       "**Our Story**\n",
       "\n",
       "HuggingFace was born out of the acquisition of our previous company, untapt, by GQR's parent company in 2021. As a co-founder and CTO of Nebula.io, we are committed to building on our legacy of applying AI to real-world problems, particularly in the field of hiring.\n",
       "\n",
       "**Our Values**\n",
       "\n",
       "* **Interdisciplinary Approach**: We believe that the best solutions come from combining diverse perspectives and expertise.\n",
       "* **Customer-Centric**: We put our customers at the heart of everything we do, ensuring that their needs are met with empathy and understanding.\n",
       "* **Innovation**: We stay ahead of the curve by investing in cutting-edge AI research and development.\n",
       "\n",
       "**Our Products**\n",
       "\n",
       "* **Nebula.io**: Our flagship product uses proprietary LLMs to help recruiters source, understand, engage, and manage talent.\n",
       "* **Connect Four**: Our arena pits LLMs against each other in a battle of diplomacy and deviousness, providing a unique glimpse into the future of AI.\n",
       "\n",
       "**Stay Connected**\n",
       "\n",
       "Follow us on LinkedIn, Twitter, or Facebook for updates on our latest products, research, and events. Join our newsletter to stay informed about the latest developments in the world of HuggingFace.\n",
       "\n",
       "**Get in Touch**\n",
       "\n",
       "If you're interested in learning more about how HuggingFace is transforming the field of talent management, please don't hesitate to connect with us. Let's chat about how we can help you succeed!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_brochure(\"HuggingFace\", \"https://edwarddonner.com\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f4642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    stream = ollama.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7116414e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'About page', 'url': 'https://edwarddonner.com/about-me-and-about-nebula/'}, {'type': 'Company page', 'url': 'https://edwarddonner.com/'}, {'type': 'Careers/Jobs page', 'url': 'mailto:hello@mygroovydomain.com'}]}\n"
     ]
    },
    {
     "ename": "InvalidSchema",
     "evalue": "No connection adapters were found for 'mailto:hello@mygroovydomain.com'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidSchema\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mstream_brochure\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHuggingFace\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://edwarddonner.com\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mstream_brochure\u001b[39m\u001b[34m(company_name, url)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstream_brochure\u001b[39m(company_name, url):\n\u001b[32m      2\u001b[39m     stream = google_client.chat.completions.create(\n\u001b[32m      3\u001b[39m         model=MODEL,\n\u001b[32m      4\u001b[39m         messages=[\n\u001b[32m      5\u001b[39m             {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: system_prompt},\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m             {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mget_brochure_user_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompany_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m}\n\u001b[32m      7\u001b[39m           ],\n\u001b[32m      8\u001b[39m         stream=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      9\u001b[39m     )\n\u001b[32m     11\u001b[39m     response = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m     display_handle = display(Markdown(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m), display_id=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mget_brochure_user_prompt\u001b[39m\u001b[34m(company_name, url)\u001b[39m\n\u001b[32m      2\u001b[39m user_prompt = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou are looking at a company called: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompany_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m user_prompt += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHere are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m user_prompt += \u001b[43mget_all_details\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m user_prompt = user_prompt[:\u001b[32m5_000\u001b[39m] \u001b[38;5;66;03m# Truncate if more than 5,000 characters\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m user_prompt\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mget_all_details\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m links[\u001b[33m\"\u001b[39m\u001b[33mlinks\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m      7\u001b[39m     result += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mlink[\u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     result += \u001b[43mWebsite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlink\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43murl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.get_contents()\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mWebsite.__init__\u001b[39m\u001b[34m(self, url)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, url):\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mself\u001b[39m.url = url\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mself\u001b[39m.body = response.content\n\u001b[32m     15\u001b[39m     soup = BeautifulSoup(\u001b[38;5;28mself\u001b[39m.body, \u001b[33m'\u001b[39m\u001b[33mhtml.parser\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\anaconda3\\envs\\llms\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\anaconda3\\envs\\llms\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\anaconda3\\envs\\llms\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\anaconda3\\envs\\llms\\Lib\\site-packages\\requests\\sessions.py:697\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    694\u001b[39m hooks = request.hooks\n\u001b[32m    696\u001b[39m \u001b[38;5;66;03m# Get the appropriate adapter to use\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m697\u001b[39m adapter = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[38;5;66;03m# Start time (approximately) of the request\u001b[39;00m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\anaconda3\\envs\\llms\\Lib\\site-packages\\requests\\sessions.py:792\u001b[39m, in \u001b[36mSession.get_adapter\u001b[39m\u001b[34m(self, url)\u001b[39m\n\u001b[32m    789\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m adapter\n\u001b[32m    791\u001b[39m \u001b[38;5;66;03m# Nothing matches :-/\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m InvalidSchema(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo connection adapters were found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mInvalidSchema\u001b[39m: No connection adapters were found for 'mailto:hello@mygroovydomain.com'"
     ]
    }
   ],
   "source": [
    "stream_brochure(\"HuggingFace\", \"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a63ed68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
